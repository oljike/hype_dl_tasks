{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "batch_size = 4\n",
    "\n",
    "dataset = datasets.CIFAR10(root=\"./data/cifar\", \n",
    "                           download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean=0.0, std=0.02)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.weight is not None:\n",
    "            m.weight.data.normal_(mean=1.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.batch_norm_1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.batch_norm_2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.batch_norm_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.batch_norm_4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_5 = nn.Conv2d(512, num_classes, kernel_size = 2, stride = 1, padding = 0)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Inputs:\n",
    "            x: (batch x 3 x 32 x 32)\n",
    "        Outputs:\n",
    "            prob: (batch x 1)\n",
    "        '''\n",
    "        x = self.conv_1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.batch_norm_3(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = self.batch_norm_4(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_5(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "    \n",
    "        return x\n",
    "\n",
    "          \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.ConvTranspose2d(z_size, 512, kernel_size = 4, stride = 1, padding = 0, bias=False)     \n",
    "        \n",
    "        self.conv_2 = nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias=False)\n",
    "        self.batch_norm_2 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_3 = nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias=False)\n",
    "        self.batch_norm_3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_4 = nn.ConvTranspose2d(128, 3, kernel_size = 4, stride = 2, padding = 1, bias=False)\n",
    "\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Inputs:\n",
    "            noise: (batch x z_size)\n",
    "        Outputs:\n",
    "            image: (batch x 3 x 32 x 32)\n",
    "        '''\n",
    "        #code here\n",
    "        image = noise.view(noise.size(0), 100, 1, 1)\n",
    "\n",
    "        \n",
    "        image = self.conv_1(image)\n",
    "        image = F.leaky_relu(image, 0.2)\n",
    "        \n",
    "        image = self.conv_2(image)\n",
    "        image = self.batch_norm_2(image)\n",
    "        image = F.leaky_relu(image, 0.2)\n",
    "        \n",
    "        image = self.conv_3(image)\n",
    "        image = self.batch_norm_3(image)\n",
    "        image = F.leaky_relu(image, 0.2)\n",
    "        \n",
    "        image = self.conv_4(image)\n",
    "        image = torch.tanh(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(11)\n",
    "xx = disc(torch.zeros(10, 3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseLoss(nn.Module):\n",
    "    def __init__(self, scale=None, observed=None):\n",
    "        super(NoiseLoss, self).__init__()\n",
    "        \n",
    "        self.scale    = 1\n",
    "        self.observed = observed\n",
    "        \n",
    "        if scale is not None:\n",
    "            self.scale = scale\n",
    "            \n",
    "    def forward(self, params):\n",
    "        noise_loss = 0.0\n",
    "        for param in params:\n",
    "            noise = torch.empty_like(param).normal_(mean=0.0, std=1.0)\n",
    "            noise_loss += self.scale * (noise * param).sum()\n",
    "        noise_loss = noise_loss / self.observed\n",
    "        return noise_loss\n",
    "    \n",
    "class PriorLoss(nn.Module):\n",
    "    def __init__(self, prior_std=1.0, observed=None):\n",
    "        super(PriorLoss, self).__init__()\n",
    "        \n",
    "        self.prior_std = prior_std\n",
    "        self.observed  = observed\n",
    "        \n",
    "    def forward(self, params):\n",
    "        prior_loss = 0.0\n",
    "        for param in params:\n",
    "            prior_loss += (param.pow(2) / self.prior_std ** 2).sum()\n",
    "        prior_loss = prior_loss / self.observed\n",
    "        return prior_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_loss(logits):\n",
    "    '''\n",
    "    Inputs:\n",
    "        logits: (batch x num_classes)\n",
    "    Outputs:\n",
    "        loss: scalar\n",
    "    '''\n",
    "    probs = F.softmax(logits, dim = -1)\n",
    "\n",
    "    log_probs = (1 - probs[:, 0] + 1e-4).log()\n",
    "\n",
    "    loss = torch.mean(-log_probs)\n",
    "\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n",
      "tensor(0.0952, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "xx = adversarial_loss(torch.ones(28, 11).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09520021826028824"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "discriminator = Discriminator(num_classes).to(device)\n",
    "\n",
    "\n",
    "\n",
    "latent_size = 100\n",
    "num_z    = 1\n",
    "num_mcmc = 4\n",
    "\n",
    "generators = []\n",
    "for generator in range(num_mcmc):\n",
    "    generator = Generator(latent_size).to(device)\n",
    "    generators.append(generator)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr    = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    \n",
    "gen_optimizers = []\n",
    "for generator in generators:\n",
    "    optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    gen_optimizers.append(optimizer)\n",
    "    \n",
    "    \n",
    "gen_noise_alpha  = 0.0001\n",
    "disc_noise_alpha = 0.0001\n",
    "\n",
    "gen_prior_criterion  = PriorLoss(prior_std=1., observed=1000.)\n",
    "gen_noise_criterion  = NoiseLoss(scale=math.sqrt(2 * gen_noise_alpha / lr), observed=1000.)\n",
    "disc_prior_criterion = PriorLoss(prior_std=1., observed=50000.)\n",
    "disc_noise_criterion = NoiseLoss(scale=math.sqrt(2 * disc_noise_alpha * lr), observed=50000.)\n",
    "\n",
    "\n",
    "epoch      = 0\n",
    "num_epochs = 25\n",
    "\n",
    "dis_losses = []\n",
    "gen_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(batch_size, latent_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generators):\n",
    "    '''\n",
    "    Inputs: \n",
    "        generators: list of generators\n",
    "    Outputs:\n",
    "        generated images: (batch * num_generators x 3 x 32 x 32)\n",
    "    '''\n",
    "       \n",
    "    noise = torch.randn(batch_size, latent_size).to(device)\n",
    "    \n",
    "    outputs = []\n",
    "    for generator in generators:\n",
    "        outputs.append(generator(noise))\n",
    "        \n",
    "    return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "output  = generate_images(generators)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch < num_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    for batch_idx, (image, _) in enumerate(dataloader):\n",
    "        image      = image.to(device) \n",
    "        batch_size = image.size(0)\n",
    "        \n",
    "        \n",
    "        #################\n",
    "        #Generate Images\n",
    "        #################\n",
    "                \n",
    "        generated_images = generate_images(generators)\n",
    "        \n",
    "        \n",
    "        #################\n",
    "        #Train Generator\n",
    "        #################\n",
    "        \n",
    "        for generator in generators:\n",
    "            generator.zero_grad()\n",
    "           \n",
    "        #####################\n",
    "        #code here###########\n",
    "        output = discriminator(generated_images)\n",
    "        gen_loss = adversarial_loss(output)\n",
    "        \n",
    "        for generator in generators:\n",
    "            gen_loss += gen_prior_criterion(generator.parameters())\n",
    "            gen_loss += gen_noise_criterion(generator.parameters())\n",
    "            \n",
    "        gen_loss.backward()\n",
    "\n",
    "        for optimizer in gen_optimizers:\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        #################################\n",
    "        #Train Discriminator on Real Data\n",
    "        #################################\n",
    "    \n",
    "        discriminator.zero_grad()\n",
    "        ########################\n",
    "        #code here##############\n",
    "        real_logits = discriminator(image)\n",
    "        real_loss   = adversarial_loss(real_logits)\n",
    "        real_loss.backward()\n",
    "        \n",
    "        #################################\n",
    "        #Train Discriminator on Fake Data\n",
    "        #################################\n",
    "        \n",
    "        fake_logits = discriminator(generated_images.detach())\n",
    "        fake_labels = torch.zeros(fake_logits.size(0)).long().to(device)\n",
    "        \n",
    "        ########################\n",
    "        #code here##############\n",
    "        fake_loss   = criterion(fake_logits, fake_labels)\n",
    "        fake_loss.backward()\n",
    "        \n",
    "        \n",
    "        ###############################\n",
    "        #Train Supervised Discriminator\n",
    "        ###############################\n",
    "        \n",
    "        \n",
    "        \n",
    "        for input_supervised, target_supervised in dataloader:\n",
    "            input_supervised, target_supervised = input_supervised.to(device), target_supervised.to(device)\n",
    "            break\n",
    "        \n",
    "        ##############################\n",
    "        #code here####################\n",
    "        logits = discriminator(input_supervised)\n",
    "        target_supervised = target_supervised + 1\n",
    "        loss_supervised   = criterion(logits, target_supervised)\n",
    "        loss_supervised.backward()\n",
    "        \n",
    "        disc_prior_criterion(discriminator.parameters()).backward()\n",
    "        disc_noise_criterion(discriminator.parameters()).backward()\n",
    "        \n",
    "        disc_optimizer.step()\n",
    "            \n",
    "            \n",
    "        if batch_idx % 100 == 0:\n",
    "            for i, generator in enumerate(generators):\n",
    "                    torchvision.utils.save_image(generator(fixed_noise).data,\n",
    "                                          '%s/%d_%d.png' % ('./bayes_gan_images', epoch, i),\n",
    "                                          normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 11])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_logits.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Домашнее задание</h1>\n",
    "<h3>1. Попробуйте прочитать самостоятельно статью и понять что такое Prior и Noise Losses</h3>\n",
    "<h3>2. В статье сказано что Bayes GAN умеет учиться классифицировать изображения в semi-supervised сеттинге. Создайте еще\n",
    "один даталоудер с датасетом 4000 картинок и обучите ган. Посчитайте accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_supervised, target_supervised in !!!!SEMI_SUPERVISED_DATALOADER!!!!!:\n",
    "    input_supervised, target_supervised = input_supervised.to(device), target_supervised.to(device)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
