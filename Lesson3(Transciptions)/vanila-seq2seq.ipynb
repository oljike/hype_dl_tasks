{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path     = 'data/transcriptions/train.csv' \n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lines   = list(reader)\n",
    "    \n",
    "_, words, trans = zip(*lines[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Shuffle and split data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle here\n",
    "\n",
    "val_size = 0.1\n",
    "train_words, val_words = #code here\n",
    "train_trans, val_trans = #code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_tokenize(line):\n",
    "    #'APPLE' -> ['A', 'P', 'L', 'L', 'E']\n",
    "    #code here\n",
    "\n",
    "def trans_tokenize(line):\n",
    "    #'AH N K AO R K' -> ['AH', 'N', 'K', 'AO', 'R', 'K']\n",
    "    #code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cound words and transcriptions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_counter = Counter()\n",
    "trans_counter = Counter()\n",
    "\n",
    "#code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, counter, sos, eos, pad, unk, min_freq=None):\n",
    "        self.sos = sos\n",
    "        self.eos = eos\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        \n",
    "        self.pad_idx = 0\n",
    "        self.unk_idx = 1\n",
    "        self.sos_idx = 2\n",
    "        self.eos_idx = 3\n",
    "        \n",
    "        self._token2idx = {\n",
    "            self.sos: self.sos_idx,\n",
    "            self.eos: self.eos_idx,\n",
    "            self.pad: self.pad_idx,\n",
    "            self.unk: self.unk_idx,\n",
    "        }\n",
    "        self._idx2token = {idx:token for token, idx in self._token2idx.items()}\n",
    "        \n",
    "        idx = len(self._token2idx)\n",
    "        min_freq = 0 if min_freq is None else min_freq\n",
    "        \n",
    "        for token, count in counter.items():\n",
    "            if count > min_freq:\n",
    "                self._token2idx[token] = idx\n",
    "                self._idx2token[idx]   = token\n",
    "                idx += 1\n",
    "        \n",
    "        self.vocab_size = len(self._token2idx)\n",
    "        self.tokens     = list(self._token2idx.keys())\n",
    "    \n",
    "    def token2idx(self, token):\n",
    "        return self._token2idx.get(token, self.pad_idx)\n",
    "    \n",
    "    def idx2token(self, idx):\n",
    "        return self._idx2token.get(idx, self.pad)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sequences, pad_idx):\n",
    "    '''\n",
    "    Inputs:\n",
    "        sequences: list of list of tokens\n",
    "    '''\n",
    "    max_length = max(map(len, sequences))\n",
    "    \n",
    "    return [seq + [pad_idx]*(max_length - len(seq)) for seq in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = \"<sos>\"\n",
    "eos = \"<eos>\"\n",
    "pad = \"<pad>\"\n",
    "unk = \"<unk>\"\n",
    "\n",
    "words_vocab = Vocab(words_counter, \n",
    "                    sos, eos, pad, unk)\n",
    "\n",
    "trans_vocab = Vocab(trans_counter, \n",
    "                    sos, eos, pad, unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tokenize data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [[words_vocab.token2idx(item) for item in words_tokenize(word)] for word in train_words]\n",
    "val_words   = [[words_vocab.token2idx(item) for item in words_tokenize(word)] for word in val_words]\n",
    "\n",
    "train_trans = [[trans_vocab.token2idx(item) for item in trans_tokenize(trans)] for trans in train_trans]\n",
    "val_trans   = [[trans_vocab.token2idx(item) for item in trans_tokenize(trans)] for trans in val_trans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, sort=False, val=False):\n",
    "    '''\n",
    "    Outputs:\n",
    "        batch_words:    (batch x seq_len)   torch.LongTensor\n",
    "        batch_trans_in: (batch x seq_len)   torch.LongTensor\n",
    "        batch_trans_out: (batch x seq_len)  torch.LongTensor\n",
    "        words_lens: (batch)                 torch.LongTensor\n",
    "        trans_lens: (batch)                 torch.LongTensor\n",
    "    '''\n",
    "        \n",
    "    #code here\n",
    "\n",
    "    return batch_words, batch_trans_in, batch_trans_out, words_lens, trans_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence  as unpack\n",
    "\n",
    "#code Encoder\n",
    "#forward(batch_words, words_lens) -> outputs, hidden\n",
    "    \n",
    "#code Decoder\n",
    "#forward(batch_trans_in, hidden) -> logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "    def forward(self, batch_words, words_lens, batch_trans_in, batch_trans_out):\n",
    "        _, hidden = self.encoder(batch_words, words_lens)\n",
    "        logits, _ = self.decoder(batch_trans_in, hidden)\n",
    "        \n",
    "        #mask = code here\n",
    "        #loss = code here\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def generate(self, sos_idx, eos_idx, batch_words):\n",
    "        '''\n",
    "        Inputs:\n",
    "            batch_words: (1 x seq_len)\n",
    "        Outputs:\n",
    "            tokens: [45, 30, 122, 4, 8, 5]\n",
    "        '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(epoch, batch_idx, train_losses, val_losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('epoch %s. | batch: %s | loss: %s' % (epoch, batch_idx, train_losses[-1]))\n",
    "    plt.plot(train_losses)\n",
    "    plt.subplot(132)\n",
    "    plt.title('epoch %s. | loss: %s' % (epoch, val_losses[-1]))\n",
    "    plt.plot(val_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare models, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print(val):\n",
    "    batch_words, batch_trans_in, batch_trans_out, words_lens, trans_lens = get_batch(1, sort=True, val=val)\n",
    "    batch_words     = batch_words.to(device)\n",
    "    batch_trans_out = batch_trans_out.to(device)\n",
    "\n",
    "\n",
    "    inp = model.generate(words_vocab.sos_idx, words_vocab.eos_idx, batch_words)\n",
    "            \n",
    "    tokens = [trans_vocab.idx2token(idx) for idx in inp if idx not in [trans_vocab.sos_idx,\n",
    "                                                                                     trans_vocab.eos_idx,\n",
    "                                                                                     trans_vocab.pad_idx]]\n",
    "    print('Src: ', ''.join([words_vocab.idx2token(idx) for idx in batch_words[0].tolist()]))\n",
    "    print('Pred:', ''.join(tokens))\n",
    "    print('Real:', ''.join([trans_vocab.idx2token(idx) for idx in batch_trans_out[0].tolist() if idx not in [trans_vocab.sos_idx,\n",
    "                                                                            trans_vocab.eos_idx,\n",
    "                                                                            trans_vocab.pad_idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    _print(True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Практика</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    \n",
    "    def get_batch(self, ):\n",
    "        pass\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    \n",
    "    def token2idx(self,):\n",
    "        pass\n",
    "    \n",
    "    def idx2token(self,):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self,):\n",
    "        pass\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        pass\n",
    "    \n",
    "    def one_train_step(self, ):\n",
    "        pass\n",
    "    \n",
    "    def one_val_step(self,):\n",
    "        pass\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        pass\n",
    "    \n",
    "    def plot(self,):\n",
    "        pass\n",
    "\n",
    "class Model:\n",
    "    def forward(self, ):\n",
    "        return loss\n",
    "    \n",
    "    def generate(self, ):\n",
    "        return pred_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
