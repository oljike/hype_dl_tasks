{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dir_A, dir_B, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "        self.dir_A = glob.glob(os.path.join(dir_A, '*.jpg'))\n",
    "        self.dir_B = glob.glob(os.path.join(dir_B, '*.jpg'))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dir_A), len(self.dir_B))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_A = Image.open(self.dir_A[idx])\n",
    "\n",
    "        image_B = Image.open(self.dir_B[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image_A = self.transform(image_A)\n",
    "            image_B = self.transform(image_B)\n",
    "\n",
    "        return image_A, image_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     25
    ]
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels=128, out_channels=128):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.padd_1 = nn.ReflectionPad2d(1)\n",
    "        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.norm_1 = nn.InstanceNorm2d(out_channels, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.padd_2 = nn.ReflectionPad2d(1)\n",
    "        self.conv_2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.norm_2 = nn.InstanceNorm2d(out_channels, affine=True, track_running_stats=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_res = self.padd_1(x)\n",
    "        x_res = self.conv_1(x_res)\n",
    "        x_res = self.norm_1(x_res)\n",
    "        x_res = F.relu(x_res)\n",
    "        \n",
    "        x_res = self.padd_2(x_res)\n",
    "        x_res = self.conv_2(x_res)\n",
    "        x_res = self.norm_2(x_res)\n",
    "\n",
    "        return x + x_res \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_bottlenecks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #Downsampling layers\n",
    "        \n",
    "        #c7s1-32\n",
    "        self.padd_1 = nn.ReflectionPad2d(3)\n",
    "        self.conv_1 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=0, bias=False)\n",
    "        self.norm_1 = nn.InstanceNorm2d(32, affine=True, track_running_stats=True)\n",
    "        \n",
    "        \n",
    "        #d64\n",
    "        self.conv_2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=True)\n",
    "        self.norm_2 = nn.InstanceNorm2d(64, affine=True, track_running_stats=True)\n",
    "        \n",
    "        #d128\n",
    "        self.conv_3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=True)\n",
    "        self.norm_3 = nn.InstanceNorm2d(128, affine=True, track_running_stats=True)\n",
    "           \n",
    "        #ResBlocks\n",
    "        self.Bottleneck = nn.Sequential(*[\n",
    "                            ResBlock(128, 128) for _ in range(num_bottlenecks)\n",
    "        ])\n",
    "        \n",
    "        #UpSampling\n",
    "        #u64\n",
    "        self.conv_4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=True)\n",
    "        self.norm_4 = nn.InstanceNorm2d(64, affine=True, track_running_stats=True)\n",
    "          \n",
    "        #u32\n",
    "        self.conv_5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=True)\n",
    "        self.norm_5 = nn.InstanceNorm2d(32, affine=True, track_running_stats=True)\n",
    "        \n",
    "        #c7s1-3\n",
    "        self.padd_6 = nn.ReflectionPad2d(3)\n",
    "        self.conv_6 = nn.Conv2d(32, 3, kernel_size=7, stride=1, padding=0, bias=True)\n",
    "        self.norm_6 = nn.InstanceNorm2d(3, affine=True, track_running_stats=True)\n",
    "   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Inputs:\n",
    "            x: (batch x 3 x 128 x 128)\n",
    "        Outputs:\n",
    "            image: (batch x 3 x 128 x 128)\n",
    "        '''\n",
    "        \n",
    "        x = self.padd_1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.norm_1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.norm_2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.norm_3(x)\n",
    "        x = F.relu(x)\n",
    "                \n",
    "        x = self.Bottleneck(x)\n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = self.norm_4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_5(x)\n",
    "        x = self.norm_5(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.padd_6(x)\n",
    "        x = self.conv_6(x)\n",
    "        x = self.norm_6(x)\n",
    "        x = torch.tanh(x)\n",
    "        \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        self.norm_2 = nn.InstanceNorm2d(128, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        self.norm_3 = nn.InstanceNorm2d(256, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(256, 512, kernel_size=4, padding=1, bias=True)\n",
    "        self.norm_4 = nn.InstanceNorm2d(512, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.conv_output = nn.Conv2d(512, 1, kernel_size=4, padding=1, bias = False)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Inputs:\n",
    "            x: (batch, 3, 128, 128)\n",
    "        Output:\n",
    "            out: (batch, 1)\n",
    "        '''\n",
    "        \n",
    "        x = self.conv_1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.norm_2(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.norm_3(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = self.norm_4(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.conv_output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_A2B = Generator(6).to(device)\n",
    "generator_B2A = Generator(6).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_A = Discriminator().to(device)\n",
    "discriminator_B = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_identity = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(itertools.chain(generator_A2B.parameters(), generator_B2A.parameters()),\n",
    "                                lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(discriminator_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(discriminator_B.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataset = MyDataset('data/trainA', 'data/trainB', transform=transforms.Compose([\n",
    "                                               transforms.Resize(128),\n",
    "                                               transforms.ToTensor()]))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "input_A = Tensor(batch_size, 3, 128, 128)\n",
    "input_B = Tensor(batch_size, 3, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset('data/testA', 'data/testB', transform=transforms.Compose([\n",
    "                                               transforms.Resize(128),\n",
    "                                               transforms.ToTensor()]))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input A is image of summer\n",
    "### Input B is image of winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while epoch<200:\n",
    "    for en, x in enumerate(dataloader):\n",
    "#         x = x.to(device)\n",
    "        \n",
    "        input_A = Tensor(x[0].size(0), 3, 128, 128)\n",
    "        input_B = Tensor(x[0].size(0), 3, 128, 128)\n",
    "        real_A = Variable(input_A.copy_(x[0])) \n",
    "        real_B = Variable(input_B.copy_(x[1]))\n",
    "        \n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        same_B = generator_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
    "        \n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = generator_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*5.0        \n",
    "        \n",
    "#         real_A = x[0].to(device)\n",
    "#         real_B = x[1].to(device)\n",
    "        \n",
    "        target_real = Variable(Tensor(real_A.size(0), 1, 14, 14).fill_(1.0), requires_grad=False)\n",
    "        target_fake = Variable(Tensor(real_B.size(0), 1, 14, 14).fill_(0.0), requires_grad=False)\n",
    "        \n",
    "        ### GENERATOR LOSS ###     \n",
    "        fake_B = generator_A2B(real_A)\n",
    "        discriminator_out_A = discriminator_B(fake_B)\n",
    "        gen_loss_A = criterion_GAN(discriminator_out_A, target_real)\n",
    "        \n",
    "        \n",
    "        fake_A = generator_B2A(real_B)    \n",
    "        discriminator_out_B = discriminator_A(fake_A)\n",
    "        gen_loss_B = criterion_GAN(discriminator_out_B, target_real)\n",
    "        \n",
    "        \n",
    "        ### Cycle loss ###\n",
    "        recovered_A = generator_B2A(fake_B)\n",
    "        cycle_loss_ABA = criterion_cycle(recovered_A, real_A) * 10.0\n",
    "        \n",
    "        recovered_B = generator_A2B(fake_A)\n",
    "        cycle_loss_BAB = criterion_cycle(recovered_B, real_B) * 10.0\n",
    "        \n",
    "        ###Total Generator Loss ###\n",
    "        generator_loss = loss_identity_B + loss_identity_A + gen_loss_A + gen_loss_B + cycle_loss_ABA + cycle_loss_BAB\n",
    "        generator_loss.backward()       \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        \n",
    "        ### Discriminator A ###\n",
    "        optimizer_D_A.zero_grad()\n",
    "        \n",
    "        pred_real_A = discriminator_A(real_A)       \n",
    "        disc_loss_real_A = criterion_GAN(pred_real_A, target_real)\n",
    "        \n",
    "        pred_fake_A = discriminator_A(fake_A.detach())\n",
    "        disc_loss_fake_A = criterion_GAN(pred_fake_A, target_fake)\n",
    "        \n",
    "        disc_loss_A = (disc_loss_real_A + disc_loss_fake_A) * 0.005\n",
    "        disc_loss_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        \n",
    "        \n",
    "        ### Discriminator B ###\n",
    "        optimizer_D_B.zero_grad()\n",
    "        \n",
    "        pred_real_B = discriminator_B(real_B)       \n",
    "        disc_loss_real_B = criterion_GAN(pred_real_B, target_real)\n",
    "        \n",
    "        pred_fake_B = discriminator_B(fake_B.detach())\n",
    "        disc_loss_fake_B = criterion_GAN(pred_fake_B, target_fake)\n",
    "        \n",
    "        disc_loss_B = (disc_loss_real_B + disc_loss_fake_B) * 0.005\n",
    "        disc_loss_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        \n",
    "                 \n",
    "    img = torchvision.utils.make_grid(torch.cat([real_B, fake_A], dim=0), nrow=4)\n",
    "    save_image(img, filename=('test_outputs/model/images/'+str(epoch)+'.jpg'))\n",
    "    \n",
    "    for en, test in enumerate(test_dataloader):\n",
    "            generator_A2B.eval()\n",
    "            real_B = Variable(test[1]).to(device)\n",
    "            fake_A = generator_B2A(real_B)\n",
    "            img = torchvision.utils.make_grid([real_B.squeeze(0), fake_A.squeeze(0)], nrow=2)\n",
    "            save_image(img, filename=('test_outputs/model/images/test'+'_'+str(epoch)+'.jpg'))\n",
    "            break\n",
    "    \n",
    "    if epoch%5==0 and epoch!=0:\n",
    "        torch.save(generator_B2A.state_dict(), 'test_outputs/model/B2A_gen_'+str(epoch)+'.pth')\n",
    "        torch.save(generator_A2B.state_dict(), 'test_outputs/model/A2B_gen_'+str(epoch)+'.pth')\n",
    "\n",
    "    print(\"The generator loss {0:2f}, discriminator A loss {1:2f}, discriminator B loss {1:2f}\".format(generator_loss.item(), disc_loss_A.item(), disc_loss_B.item()))\n",
    "    epoch += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_list = [transforms.Resize(128),\n",
    "                                               transforms.ToTensor()\n",
    "                  ]\n",
    "\n",
    "\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "landmarkk_test = Image.open('face_dataset/celeba/devushka_test.jpg')#.convert('L')\n",
    "#landmarkk_test = landmarkk_test.resize((256, 128), Image.BICUBIC)\n",
    "landmarkk_test = transform(landmarkk_test)\n",
    "landmarkk_test = landmarkk_test.to(device)\n",
    "\n",
    "\n",
    "fake_test = model.eval(landmarkk_test.unsqueeze(0))\n",
    "print(fake_test.shape)\n",
    "print(landmarkk_test.shape)\n",
    "\n",
    "test_img = torchvision.utils.make_grid([landmarkk_test.repeat(3, 1, 1).cpu(), fake_test.squeeze(0).cpu()], nrow=3)\n",
    "save_image(test_img.squeeze(0), filename=('devushka_fake_test'+str(epoch)+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset('data/testA', 'data/testB', transform=transforms.Compose([\n",
    "                                               transforms.Resize(128),\n",
    "                                               transforms.ToTensor()]))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "for en, test in enumerate(test_dataloader):\n",
    "    generator_A2B.eval()\n",
    "    real_B = Variable(test[1]).to(device)\n",
    "    fake_A = generator_B2A(real_B)\n",
    "    img = torchvision.utils.make_grid([real_B.squeeze(0), fake_A.squeeze(0)], nrow=2)\n",
    "    save_image(img, filename=('test_outputs/model/images/test'+'_'+str(epoch)+'.jpg'))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
